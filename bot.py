import os
import json
import requests
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Ø¯Ø±ÛŒØ§ÙØª ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø§Ø² Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
HF_API_KEY = os.getenv("HF_API_KEY")

# ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§
MODELS = {
    "deepseek-llm-7b": "https://api-inference.huggingface.co/models/deepseek-ai/deepseek-llm-7b",
    "deepseek-v3": "https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-V3",
    "janus-pro-7b": "https://api-inference.huggingface.co/models/deepseek-ai/Janus-Pro-7B",
    "mt5-small": "https://api-inference.huggingface.co/models/google/mt5-small",  # mT5-small
}

# Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
DEFAULT_MODEL = "deepseek-v3"

# Ø­Ø§ÙØ¸Ù‡ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø¯Ø§Ø®Ù„ÛŒ - Ø¨Ø±Ø§ÛŒ Ø­Ø§Ù„Øª Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª Ø¨Ø§ÛŒØ¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø§Ø¶Ø§ÙÙ‡ Ø´ÙˆØ¯)
memory = []

# --- Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Ù…Ø¯Ù„ Hugging Face (Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù) ---
def query_huggingface(prompt, model_name=DEFAULT_MODEL):
    headers = {
        "Authorization": f"Bearer {HF_API_KEY}",
        "Content-Type": "application/json",
    }
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_length": 500,  # Ø§ÙØ²Ø§ÛŒØ´ Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø®
            "temperature": 0.7,  # ØªÙ†Ø¸ÛŒÙ… Ø¯Ù…Ø§
            "top_k": 50,  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§
            "top_p": 0.9,  # ØªÙ†Ø¸ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÙˆØ¹â€ŒØªØ±
        },
    }
    
    try:
        response = requests.post(
            MODELS[model_name],  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø¯Ø±Ø³ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ
            headers=headers,
            json=payload,
        )
        result = response.json()
        if isinstance(result, list) and len(result) > 0 and "generated_text" in result[0]:
            return result[0]["generated_text"]
        return result.get("error", "Ù…ØªÙˆØ¬Ù‡ Ù†Ø´Ø¯Ù…ØŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ù¾Ø±Ø³ÛŒØ¯.")
    except Exception as e:
        return f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„: {str(e)}"

# --- ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ Hugging Face ---
async def test_huggingface(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        test_response = query_huggingface("Ø³Ù„Ø§Ù…ØŒ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ø¯ÛŒØŸ")
        await update.message.reply_text(f"âœ… ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ Hugging Face Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø¨ÙˆØ¯:\n{test_response}")
    except Exception as e:
        await update.message.reply_text(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Hugging Face:\n{str(e)}")

# --- ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Hugging Face Ø¨Ø§ ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø´Ø®Øµ ---
async def test_huggingface_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    prompt = "Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø± Ú†ÛŒØ³ØªØŸ"
    response = query_huggingface(prompt)
    await update.message.reply_text(
        f"âœ… ØªØ³Øª Ù…Ø¯Ù„ Hugging Face Ø¨Ø§ ÙˆØ±ÙˆØ¯ÛŒ Ù†Ù…ÙˆÙ†Ù‡:\n"
        f"ğŸ“ Ù¾Ø±Ø³Ø´: {prompt}\n"
        f"ğŸ§  Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„:\n{response}"
    )

# --- Ø¯Ø³ØªÙˆØ± Ø´Ø±ÙˆØ¹ (Ø±Ø§Ù‡Ù†Ù…Ø§) ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ‘‹ Ø³Ù„Ø§Ù…! Ù…Ù† Ø±Ø¨Ø§Øª Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù‡Ø³ØªÙ…. Ø¯Ø³ØªÙˆØ±Ø§Øª ØªØ³Øª:\n"
        "ğŸ”§ /test_telegram - ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…\n"
        "ğŸ’¡ /test_huggingface - ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ Hugging Face\n"
        "ğŸ§ª /test_huggingface_model - ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Hugging Face\n"
        "ğŸ“š /article [Ù…ØªÙ† Ù…Ù‚Ø§Ù„Ù‡] - Ø°Ø®ÛŒØ±Ù‡ Ù…Ù‚Ø§Ù„Ù‡\n"
        "ğŸ› ï¸ /set_model [Ù†Ø§Ù… Ù…Ø¯Ù„] - ØªØºÛŒÛŒØ± Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ\n"
        "ğŸ” /show_model - Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ\n"
        "âœ‰ï¸ Ù¾ÛŒØ§Ù… Ù…Ø³ØªÙ‚ÛŒÙ… - Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù…Ø¯Ù„ Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø®\n"
        "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:\n" + "\n".join(MODELS.keys())
    )

# --- Ø°Ø®ÛŒØ±Ù‡ Ù…Ù‚Ø§Ù„Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø¯Ø§Ø®Ù„ÛŒ ---
async def save_article(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if context.args:
        article = " ".join(context.args)
        memory.append({"role": "article", "content": article})
        await update.message.reply_text("âœ… Ù…Ù‚Ø§Ù„Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ùˆ Ø¯Ø± Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.")
    else:
        await update.message.reply_text("âš ï¸ Ù„Ø·ÙØ§Ù‹ Ù…Ù‚Ø§Ù„Ù‡ Ø±Ø§ Ù¾Ø³ Ø§Ø² Ø¯Ø³ØªÙˆØ± /article ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")

# --- Ø¯Ø³ØªÙˆØ± Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ù…Ø¯Ù„ ---
async def set_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if context.args:
        model_name = context.args[0]
        if model_name in MODELS:
            context.user_data["current_model"] = model_name
            await update.message.reply_text(f"âœ… Ù…Ø¯Ù„ Ø¨Ù‡ {model_name} ØªØºÛŒÛŒØ± ÛŒØ§ÙØª.")
        else:
            await update.message.reply_text("âš ï¸ Ù…Ø¯Ù„ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:\n" + "\n".join(MODELS.keys()))
    else:
        await update.message.reply_text("âš ï¸ Ù„Ø·ÙØ§Ù‹ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø±Ø§ Ù¾Ø³ Ø§Ø² Ø¯Ø³ØªÙˆØ± /set_model ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")

# --- Ø¯Ø³ØªÙˆØ± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ ---
async def show_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    current_model = context.user_data.get("current_model", DEFAULT_MODEL)
    await update.message.reply_text(f"ğŸ› ï¸ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ: {current_model}")

# --- Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ùˆ Ù¾Ø§Ø³Ø® Ø§Ø² Ù…Ø¯Ù„ ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    memory.append({"role": "user", "content": user_message})
    
    # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ Ø¨Ù‡ Ûµ Ù¾ÛŒØ§Ù… Ø§Ø®ÛŒØ±
    if len(memory) > 5:
        memory.pop(0)
    
    context_str = "\n".join([f"{m['role']}: {m['content']}" for m in memory])
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ú©Ø§Ø±Ø¨Ø± (ÛŒØ§ Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶)
    current_model = context.user_data.get("current_model", DEFAULT_MODEL)
    response = query_huggingface(context_str, model_name=current_model)
    
    memory.append({"role": "assistant", "content": response})
    await update.message.reply_text(response)

# --- ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… ---
async def test_telegram(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ù‚Ø±Ø§Ø± Ø§Ø³Øª.")

# --- Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ ---
def main():
    application = Application.builder().token(TELEGRAM_TOKEN).build()

    # Ø§ÙØ²ÙˆØ¯Ù† Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ±Ø§Øª Ùˆ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("article", save_article))
    application.add_handler(CommandHandler("test_telegram", test_telegram))
    application.add_handler(CommandHandler("test_huggingface", test_huggingface))
    application.add_handler(CommandHandler("test_huggingface_model", test_huggingface_model))
    application.add_handler(CommandHandler("set_model", set_model))  # Ø¯Ø³ØªÙˆØ± Ø¬Ø¯ÛŒØ¯
    application.add_handler(CommandHandler("show_model", show_model))  # Ø¯Ø³ØªÙˆØ± Ø¬Ø¯ÛŒØ¯
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    application.run_polling()

if __name__ == '__main__':
    main()